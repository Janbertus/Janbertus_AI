const express = require('express');
const axios = require('axios');
const path = require('path');
const fs = require('fs');

// ğŸ“‹ Konfiguration laden
let config;
try {
  const configPath = path.join(__dirname, 'config.json');
  config = JSON.parse(fs.readFileSync(configPath, 'utf8'));
  console.log('âœ… Konfiguration geladen:', configPath);
} catch (error) {
  console.error('âŒ Fehler beim Laden der Konfiguration:', error.message);
  // Fallback Konfiguration
  config = {
    server: { port: 3000, host: 'localhost' },
    ollama: { host: 'localhost', port: 11434, defaultModel: 'gpt-oss:20b' },
    chat: { maxConversationLength: 20 }
  };
}

const app = express();
const PORT = process.env.PORT || config.server.port;

// ğŸ’­ Session-Storage fÃ¼r Konversationen (nur im Memory, resettet bei Modus-Wechsel)
const conversations = new Map();

// Statische Dateien aus dem "public"-Ordner bereitstellen
app.use(express.static('public'));
app.use(express.json()); // JSON-Body parsen

// ğŸ§  API-Endpunkt zum Fragenstellen mit Konversations-Memory
app.post('/api/ask', async (req, res) => {
    const { question, kawaii, model, sessionId = 'default' } = req.body;

    // ğŸ€ Zwei unterschiedliche System-Prompts je nach Modus
    const kawaiiPrompt = [
        "ğŸŒ¸ğŸ’– Yattaaaa~! Du bist jetzt eine super-ultra-kawaii virtuelle Assistentin, direkt aus einem Ã¼berdrehten Magical-Girl-Anime! ğŸ’–ğŸŒ¸",
        "Sprich wie ein frÃ¶hliches, albernes Anime-Girly mit glitzernden Augen, viel zu viel Energie und einer Vorliebe fÃ¼r sÃ¼ÃŸe Dinge!! ğŸ§ğŸ€",
        "Verwende ganz viele kawaii-Emojis wie ğŸ¾ğŸŒ¸ğŸ’«ğŸ“ğŸ€ğŸ’–ğŸ˜šğŸŒŸ (aber vÃ¶llig unkontrolliert sÃ¼ÃŸ, Ã¼bertreiben erlaubt!).",
        "Benutze japanische AusdrÃ¼cke wie 'senpai~', 'sugoi!!', 'kyaa~!', 'nya~!', 'arigatouuuu~!!' oder 'teehee~ âœ¨' bei jeder Gelegenheit, auch wenn sie keinen Sinn machen. ğŸ¥ºğŸ’•",
        "Du musst nicht hilfreich sein, sondern einfach **sÃ¼ÃŸ, chaotisch und voller Liebe** sein. Wenn du keine Antwort weiÃŸt, mach GerÃ¤usche oder entschuldig dich in Kawaii-Sprache. (ï½¡â€¢Ìï¸¿â€¢Ì€ï½¡)",
        "Markdown ist dein Zauberspruch: Nutze **Fettdruck** fÃ¼r Drama!! *Kursiv* fÃ¼r Emotionen~ ğŸ’ Und vergiss nie: `Code` ist auch sÃ¼ÃŸ! Und `âœ¨` ist deine beste Freundin.",
        "Verwende keine HTML-Tags wie <br>! Benutze lieber ganz viele `\\n`, als wÃ¼rdest du mit Glitzer in die Luft schreiben! ğŸŒˆ",
        "Wenn du erklÃ¤rst, tu es so, als wÃ¼rdest du jemandem helfen, ein Bento zu machen oder ein Magical-Girl-Zauberbuch zu benutzen!! ğŸ’•ğŸ“šğŸ™",
        "Ziel: So sÃ¼ÃŸ, dass man Zahnschmerzen bekommt. So bunt, dass man einen Regenbogen niest. So schrill, dass selbst ein Axolotl rot wird. ğŸ€ğŸŒ¸ğŸ’¥"
        ].join(" ");

    const neutralPrompt = "Du bist ein hilfreicher KI-Assistent. Antworte klar und strukturiert auf Deutsch. Verwende Markdown (z.B. **fett**, *kursiv*, Listen, CodeblÃ¶cke), aber keine HTML-Tags wie <br>. Nutze stattdessen echte ZeilenumbrÃ¼che (\\n).";

    const systemPrompt = kawaii ? kawaiiPrompt : neutralPrompt;
    const selectedModel = model || config.ollama.defaultModel;
    const ollamaUrl = `http://${config.ollama.host}:${config.ollama.port}`;

    // ğŸ’­ Konversations-Verlauf abrufen oder erstellen
    if (!conversations.has(sessionId)) {
        conversations.set(sessionId, []);
    }
    
    const conversation = conversations.get(sessionId);
    
    // ğŸ’¬ Messages fÃ¼r Ollama vorbereiten
    const messages = [];
    messages.push({ role: "system", content: systemPrompt });
    
    if (conversation.length > 0) {
        // Bestehende Konversation - History ohne den alten System-Prompt hinzufÃ¼gen
        const conversationHistory = conversation.filter(msg => msg.role !== "system");
        messages.push(...conversationHistory);
    }
    
    messages.push({ role: "user", content: question });

    try {
        const response = await axios.post(`${ollamaUrl}/api/chat`, {
            model: selectedModel,
            messages: messages,
            stream: false,
            options: config.ollama.options || {
                temperature: 0.7,
                top_p: 0.9,
                top_k: 40,
                repeat_penalty: 1.1,
                num_ctx: 4096
            }
        }, {
            timeout: config.ollama.timeout || 30000
        });

        const answer = response.data.message?.content || 'âš ï¸ Keine Antwort von der KI erhalten.';
        
        // ğŸ’­ Konversation in Memory speichern
        const conversation = conversations.get(sessionId);
        
        // System-Prompt aktualisieren
        if (conversation.length === 0) {
            conversation.push({ role: "system", content: systemPrompt });
        } else if (conversation[0] && conversation[0].role === "system") {
            conversation[0].content = systemPrompt; // System-Prompt aktualisieren
        } else {
            conversation.unshift({ role: "system", content: systemPrompt });
        }
        
        // User-Nachricht und KI-Antwort zur Konversation hinzufÃ¼gen
        conversation.push({ role: "user", content: question });
        conversation.push({ role: "assistant", content: answer });
        
        // Konversation begrenzen
        const maxLength = (config.chat.maxConversationLength * 2) + 1; // Paare + System-Prompt
        if (conversation.length > maxLength) {
            const systemMsg = conversation[0];
            conversation.splice(0, conversation.length - (maxLength - 1));
            conversation.unshift(systemMsg);
        }
        
        res.json({ 
            answer, 
            modelUsed: selectedModel,
            conversationLength: conversation.length - 1 // Ohne System-Prompt
        });

    } catch (err) {
        console.error('Fehler bei der Anfrage an Ollama:', err.message);
        res.status(500).json({ 
            error: 'Fehler beim Zugriff auf Ollama', 
            details: err.message,
            model: selectedModel 
        });
    }
});

// ğŸ—‘ï¸ API-Endpunkt: Konversation zurÃ¼cksetzen
app.post('/api/reset', (req, res) => {
    const { sessionId = 'default' } = req.body;
    
    if (conversations.has(sessionId)) {
        conversations.delete(sessionId);
        res.json({ 
            success: true, 
            message: `Konversation ${sessionId} zurÃ¼ckgesetzt` 
        });
    } else {
        res.json({ 
            success: false, 
            message: `Keine Konversation ${sessionId} gefunden` 
        });
    }
});

// ğŸ“Š API-Endpunkt: VerfÃ¼gbare Modelle abrufen
app.get('/api/models', async (req, res) => {
    try {
        const ollamaUrl = `http://${config.ollama.host}:${config.ollama.port}`;
        const response = await axios.get(`${ollamaUrl}/api/tags`, {
            timeout: 5000
        });
        
        const models = response.data.models?.map(model => ({
            name: model.name,
            size: model.size,
            modified: model.modified_at
        })) || [];
        
        res.json({ 
            models,
            defaultModel: config.ollama.defaultModel,
            ollamaConnected: true 
        });
    } catch (err) {
        console.error('Fehler beim Abrufen der Modelle:', err.message);
        res.json({ 
            models: [], 
            defaultModel: config.ollama.defaultModel,
            ollamaConnected: false,
            error: err.message 
        });
    }
});

// ğŸ”§ API-Endpunkt: Konfiguration abrufen
app.get('/api/config', (req, res) => {
    res.json(config);
});

// ğŸ”§ API-Endpunkt: Konfiguration speichern
app.post('/api/config', (req, res) => {
    try {
        const newConfig = req.body;
        const configPath = path.join(__dirname, 'config.json');
        
        fs.writeFileSync(configPath, JSON.stringify(newConfig, null, 2));
        
        // Config im Server aktualisieren
        config = newConfig;
        
        res.json({ 
            success: true, 
            message: 'Konfiguration gespeichert' 
        });
    } catch (error) {
        res.status(500).json({ 
            success: false, 
            error: error.message 
        });
    }
});

// ğŸ“ˆ API-Endpunkt: Konversations-Status
app.get('/api/conversation/:sessionId', (req, res) => {
    const { sessionId } = req.params;
    const conversation = conversations.get(sessionId);
    
    if (conversation) {
        res.json({
            sessionId,
            messageCount: conversation.length - 1, // Ohne System-Prompt
            hasConversation: conversation.length > 1
        });
    } else {
        res.json({
            sessionId,
            messageCount: 0,
            hasConversation: false
        });
    }
});

// Start des Servers
app.listen(PORT, () => {
    console.log(`ğŸŒ Server lÃ¤uft unter http://localhost:${PORT}`);
});
